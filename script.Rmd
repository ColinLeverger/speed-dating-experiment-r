---
title: 'Exploring Speed Dating'
author: 'Colin LEVERGER'
date: '22 Oct 2016'
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: yeti
    highlight: tango
---
# Introduction

I am going to explore a Speed Dating dataset provided by Kaggle, which can be found at the following URL: https://www.kaggle.com/annavictoria/speed-dating-experiment/.

```{r, include=FALSE}
setwd("/Users/colinleverger/Documents/Experiments/kaggle/speed-dating-experiment")
```

The dataset is provided with its key, which is a Word document you will need to quickly go through to understand my work properly.

# Initialisations
****
## Packages

Let's first load a few libraries...

```{r, results="hide", warning=FALSE, message=FALSE}
# Load libraries & packages
library(dplyr)        # Data manipulation
library(reshape2)     # Data reshaping for ggplot
library(ggplot2)      # Data visualization
library(RColorBrewer) # Colors on plots
library(readr)        # CSV file I/O, e.g. the read_csv function
library(dataQualityR) # DQR generation
library(randomForest) # Random Forest for variable importance
```

## Color palettes for plots

This is optional, but if we decide to change the color of the `ggplot` afterwards, it could be useful.

```{r}
cbPalette  <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

## Read the data
```{r, results="hide", warning=FALSE, message=FALSE}
missing.types <- c("NA", "")
df <- read.csv("input/Speed Dating Data.csv", na.strings = missing.types, stringsAsFactors = F)
# "income", "tuition" and "mn_sat" features should be read as numerical
df$income  <- as.numeric(gsub(",", "", df$income))
df$tuition <- as.numeric(gsub(",", "", df$tuition))
df$mn_sat  <- as.numeric(gsub(",", "", df$mn_sat))
```

# Clean the data
****
In this part of the analysis, we will clean the dataset and work on variables to have a better exploration of the dataset. This procedure includes various checks, imputations, type changes...

## Generate the Data Quality Report, before the feature engineering

The Data Quality Report (DQR) is a good way to have an overall view of the quality of the dataset. Which feature has the most missing values? How many unique values are present for this or this feature? Etc. It is a very good help to understand and clean the data.

```{r}
checkDataQuality(
  df,
  out.file.num = "dqr/DQR_cont.csv",
  out.file.cat = "dqr/DQR_cat.csv"
)

# Read the DQR on the disk
dqr.cont <- read.csv("dqr/DQR_cont.csv")
dqr.cat  <- read.csv("dqr/DQR_cat.csv")

# Classify features in function of their missingness for better analysis
feat.cont.missing20_100 <- dqr.cont[dqr.cont$missing.percent > 20,]
feat.cont.missing20     <- dqr.cont[dqr.cont$missing.percent <= 20 & dqr.cont$missing.percent > 0,]
# View(feat.cont.missing20)
```

## Imputations with missing values

If we take a closer look at the data, we notice that there are a lot of features which have exactly 79 missing values.

```{r}
head(dqr.cont[dqr.cont$missing == 79, c(1,2,3)], 10)
```

The question is: is there a pattern? Can we impute, can we clean up this mess?

```{r}
val1 <- feat.cont.missing20[feat.cont.missing20$missing == 79,]$X
sample_n(df[is.na(df$imprelig), c(1:10)], 10)
```

It appears that nothing very interesting can be deducted from this. Indeed, most of the missing values are preferences of the people considered. Impossible to impute that!

In the same approach, there is a lot of missing values for `age_o` and `race_o` features.

```{r}
missing.age_o.pid <- unique(df[is.na(df$age_o),]$pid)
missing.race_o.pid <- unique(df[is.na(df$race_o),]$pid)
sample_n(subset(df, iid %in% missing.age_o.pid)[, c(1:10)], 10)
```

Nothing very interesting here neither.

## Deal with missing id

According to our DQR, there is one missing `id` in our dataset. It should be fairly easy to deduct the good value. Let's find and replace it.

```{r}
# Find the iid of the only missing id
iid <- df[is.na(df$id),]$iid
# Assign this iid' id to the missing iid..
df[is.na(df$id),]$id <- head(df[df$iid == iid,]$id, 1)
```

_Note to myself: it is not useful to make the process generic, the data will not change anyway..._
 
## Deal with missing pid

There is 10 missing `pid` (partner’s iid number) in the dataset. Since there is no `iid` missing, we could probably impute quite easily. 

Every person has an unique id in the entire dataset: `iid`. A person has also an unique identifier within the wave: `id`. Each person meet another person, and we have both the `iid` and the `id` of this person met (respectively mapped to `pid` and `partner`). Therefore, if there is 10 `pid` missing and no `partner` missing, the `partner` value will lead us within the wave to this missing `pid`.

```{r}
# Show the missing pid
df[is.na(df$pid), c(1,2,11,12)]
# Save the partner number for the wave
partner.pid <- unique(df[is.na(df$pid),]$partner)
# Save the wave number
wave.pid <- unique(df[is.na(df$pid),]$wave)
# Show the iid we are looking for
unique(df[df$wave == wave.pid & df$id == partner.pid,]$iid)
df[is.na(df$pid),]$pid <- 128
```

## Work on field feature
```{r}
# Plot raw field
df$field <- tolower(df$field)
barplot(
  table(df$field),
  main = "Careers"
)

# How many unique field do we have?
paste("There is", length(unique(df$field)), "different uncoded fields.")
```

We cannot use this column to analyse the data. Indeed, all the values in this column were directly given by the users, and the latter may write anything, including nonsense values such as "I don’t know".

Instead, we will rely on the `field_coded` variable, which should have 18 levels.

```{r}
# Show coded field
ordered(unique(df$field_cd))
```

## Work on career feature
```{r}
# Plot raw career
df$career <- tolower(df$career)
barplot(
  table(df$career),
  main = "Careers"
)
# How many unique carrer do we have?
paste("There is", length(unique(df$career)), "different uncoded carreers.")

# Show coded career (should have 17 levels)
ordered(unique(df$career_c))
```

## Work on zip codes

We see that there is a lot of `zipcode`s equals to 0, and these should be changed to NAs.

```{r}
# Assign NA to all the zip codes equals to 0
df[df$zipcode == 0 & !is.na(df$zipcode),]$zipcode <- NA
```

## Standardise waves

It is said on the word doc linked to the data that the waves 6 to 9 are different because people were asked to note their preferences from 1 to 10 rather than allocating a hundred points on features.

```{r}
# Show waves 6 to 9
head(df[df$wave > 5 & df$wave < 10, c(1,16:20)])
# Show wave 3 to compare
head(df[df$wave == 3, c(1,16:20)])
```

However, we see above that the data seems to already be standardised - no work for us here!

## Change Male and Female attributes

To enhance comprehension, I have chosen to display `W` instead if `0` for women, and `M` instead of `1` for males. This little modification will not have any negative impact on analysis, because we will not do any machine learning.

```{r}
df[df$gender == 0,]$gender <- "W"
df[df$gender == 1,]$gender <- "M"
```

# Analyse the data
****
## Gender analysis
```{r, warning=FALSE, message=FALSE}
gender.rep.over.waves <- subset(df, !duplicated(df[, 1])) %>%
  group_by(wave, gender) %>%
  summarise(my.n = n()) %>%
  melt(id.vars = c("gender", "wave"))

# Plot gender repartition in waves
ggplot(gender.rep.over.waves, aes(x = wave, y = value, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Wave") + ylab("Population") + ggtitle("Gender repartition in waves") +
  scale_fill_manual(values = cbPalette)
```

## Age analysis
```{r, warning=FALSE, message=FALSE}
age.rep.over.waves <- subset(df, !duplicated(df[, 1])) %>%
  filter(!is.na(age)) %>%
  group_by(wave, gender) %>%
  summarise(my.m = mean(age)) %>%
  melt(id.vars = c("gender", "wave"))

# Plot age repartition in waves
ggplot(age.rep.over.waves, aes(x = wave, y = value, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Wave") + ylab("Mean age") + ggtitle("Age repartition in waves") +
  scale_fill_manual(values = cbPalette)

# What are the extremums?
print(paste0("Minimum age in all the dataset is: ", min(df[!is.na(df$age),]$age)))
print(paste0("Max age in all the dataset is: ", max(df[!is.na(df$age),]$age)))
print(paste0("Mean age in all the dataset is: ", mean(df[!is.na(df$age),]$age)))
```

## Work and studies analysis
```{r}
# Create study field codes
fields.cd <- c(
  "Law",
  "Math",
  "Social Science, Psychologist" ,
  "Medical Science, Pharmaceuticals, and Bio Tech",
  "Engineering",
  "English/Creative Writing/ Journalism",
  "History/Religion/Philosophy",
  "Business/Econ/Finance",
  "Education, Academia",
  "Biological Sciences/Chemistry/Physics",
  "Social Work" ,
  "Undergrad/undecided" ,
  "Political Science/International Affairs" ,
  "Film",
  "Fine Arts/Arts Administration",
  "Languages",
  "Architecture",
  "Other"
)

# Create career codes
career.cd <- c(
  "Lawyer",
  "Academic/Research", 
  "Psychologist", 
  "Doctor/Medicine",
  "Engineer", 
  "Creative Arts/Entertainment",
  "BankingBusiness/CEO/Admin",
  "Real Estate",
  "International/Humanitarian Affairs",
  "Undecided" ,
  "Social Work",
  "Speech Pathology",
  "Politics",
  "Pro sports/Athletics",
  "Other",
  "Journalism",
  "Architecture"
)

# Find number of men/women on each study field
fields <- df[!is.na(df$field_cd),] %>%
  group_by(gender, field_cd) %>%
  summarise(
    my.n = n()
  )

# Find number of men/women on each career
careers <- df[!is.na(df$career_c),] %>%
  group_by(gender, career_c) %>%
  summarise(
    my.n = n()
  )

# Plot study fields repartition
ggplot(fields, aes(x = field_cd, y = my.n, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Field") + ylab("Count") + ggtitle("Study fields repartition") +
  scale_x_continuous(labels = fields.cd, breaks = 1:18) +
  coord_flip()

# Plot careers repartition
ggplot(careers, aes(x = career_c, y = my.n, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Career") + ylab("Count") + ggtitle("Careers repartition") +
  scale_x_continuous(labels = career.cd, breaks = 1:17) +
  coord_flip()
```

## Race analysis
```{r}
# Create race code
race.c <- c(
  "Black/African American",
  "European/Caucasian-American",
  "Latino/Hispanic American",
  "Asian/Pacific Islander/Asian-American",
  "Native American",
  "Other"
)

# Find number of men/women for each race
races <- df[!is.na(df$race),] %>%
  group_by(gender, race) %>%
  summarise(
    my.n = n()
  )

# Plot race repartition
ggplot(races, aes(x = race, y = my.n, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Race") + ylab("Count") + ggtitle("Race repartition") +
  scale_x_continuous(labels = race.c, breaks = 1:6) +
  coord_flip()
```

## Goal analysis
```{r}
# Create goal code
goal.c <- c(
  "Seemed like a fun night out",
  "To meet new people",
  "To get a date",
  "Looking for a serious relationship",
  "To say I did it",
  "Other"
)

# Find number of men/women for each goal
goals <- df[!is.na(df$goal),] %>%
  group_by(gender, goal) %>%
  summarise(
    my.n = n()
  )

# Plot goals repartition
ggplot(goals, aes(x = goal, y = my.n, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Goal") + ylab("Count") + ggtitle("Goal repartition") +
  scale_x_continuous(labels = goal.c, breaks = 1:6) +
  coord_flip()
```

## Date & go out analysis
```{r}
# Create date & go out code
date.c <- c(
  "Several times a week",
  "Twice a week",
  "Once a week",
  "Twice a month",
  "Once a month",
  "Several times a year",
  "Almost never"
)

# Find date occurrence for men/women
dates <- df[!is.na(df$date),] %>%
  group_by(gender, date) %>%
  summarise(
    my.n = n()
  )

# Find go out occurrence for men/women
go.outs <- df[!is.na(df$go_out),] %>%
  group_by(gender, go_out) %>%
  summarise(
    my.n = n()
  )

# Plot dates repartition
ggplot(dates, aes(x = date, y = my.n, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Date") + ylab("Count") + ggtitle("Date repartition") +
  scale_x_continuous(labels = date.c, breaks = 1:7) +
  coord_flip()

# Plot go out repartition
ggplot(go.outs, aes(x = go_out, y = my.n, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") +
  xlab("Go out") + ylab("Count") + ggtitle("Go out repartition") +
  scale_x_continuous(labels = date.c, breaks = 1:7) +
  coord_flip()
```

## Matches analysis
```{r}
# Dummie analysis on Matches
barplot(
  table(df$match),
  main = "Matches proportion",
  col = "black"
)
```

### Match by gender analysis
```{r}
match.by.gender <- df %>%
  group_by(gender) %>%
  summarise(
    nb_matches = sum(match == 1),
    nb_fails = sum(match == 0)
  ) %>% 
  melt(id.vars = "gender")

# Plot matches for both men and women
ggplot(match.by.gender, aes(x = variable, y = value, fill = factor(gender))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_discrete(name = "Gender") + ggtitle("Matches by gender") +
  xlab("Result") + ylab("Count")
```

### Match by wave analysis
```{r}
match.by.waves <- df[df$match == 1,] %>%
  group_by(wave) %>%
  summarise(
    nb_matches = sum(match == 1)
  )

# Plot matches for waves: what was the best wave to be?
ggplot(match.by.waves, aes(x = wave, y = nb_matches)) +
  geom_bar(stat = "identity", position = "dodge") + ggtitle("Matches by waves") +
  xlab("Wave number") + ylab("Matches")
```

## Look for best attributes to have
### For men
#### Preminilary analysis
```{r}
# Isolate the men from the dataset
men <- df[df$gender == "M",]

# Get first and last index of the columns of the features we are interested in
first.col.index <- head(grep("sports", colnames(df)), 1)
last.col.index  <- head(grep("yoga", colnames(df)), 1)

# Get index of the `match` column
match.col.index <- head(grep("match", colnames(df)), 1)

# Create vector without NAs to use forest
men <- men[complete.cases(men[first.col.index:last.col.index]),]

# Group men by iid
men.grouped.iid <- men %>%
  group_by(iid) %>%
  summarise(
    sum.match = sum(match)
  ) 

# Find the number of men per number of matches
n.match.men <- men.grouped.iid %>%
  group_by(sum.match) %>%
  summarise(
    my.n = n()
  )

# Plot number of match per man
ggplot(n.match.men, aes(x = sum.match, y = my.n)) +
  geom_bar(stat = "identity", position = "dodge", fill="#E69F00", colour="black") +
  xlab("Number of matches") + ylab("Count") + ggtitle("Number of men per number of matches")
```

#### Dummie feature importance analysis

```{r}
# Isolate men with matches
men.matches <-  men[df$match == 1,] 

# Dummie analysis: summarise the number of occurence of each features
dum <- men.matches %>%
  group_by(gender) %>%
  summarise(
    s.sports = sum(sports, na.rm=T),
    s.tvsports = sum(tvsports, na.rm=T),
    s.exercise = sum(exercise, na.rm=T),
    s.dining = sum(dining, na.rm=T),
    s.museums = sum(museums, na.rm=T),
    s.art = sum(art, na.rm=T),
    s.hiking = sum(hiking, na.rm=T),
    s.gaming = sum(gaming, na.rm=T),
    s.clubbing = sum(clubbing, na.rm=T),
    s.reading = sum(reading, na.rm=T),
    s.tv = sum(tv, na.rm=T),
    s.music = sum(music, na.rm=T),
    s.theater = sum(theater, na.rm=T),
    s.movies = sum(movies, na.rm=T),
    s.concerts = sum(concerts, na.rm=T),
    s.shopping = sum(shopping, na.rm=T),
    s.yoga = sum(yoga, na.rm=T)
  ) %>%
  melt(id.vars = "gender")

ggplot(dum[,c(2,3)], aes(x = reorder(variable, -value), y = value)) +
  geom_bar(stat = "identity", position = "dodge", fill="#56B4E9", colour="black") +
  xlab("Feature") + ylab("Count") + ggtitle("Importance of a feature") +
  coord_flip()
```

#### Simple Random Forest classifier

```{r}
# Set the random seed to make this result reproducible
set.seed(50)
# Feed a randomForest model
fit <- randomForest(as.factor(match) ~ sports + tvsports + exercise + 
              dining + museums + art + hiking + music + gaming + clubbing + 
              reading + tv + theater + movies + concerts + shopping + yoga,
          data = men,
          importance=TRUE, 
          ntree=2000
)

# Get the importance of the features
importance.features <- tibble::rownames_to_column(data.frame(fit$importance[,c(1)]))
colnames(importance.features) <- c("rowname", "value")

# Plot the importance of the features for a man
ggplot(importance.features, aes(x = reorder(rowname, -value), y = value)) +
  geom_bar(stat = "identity", position = "dodge", fill="#56B4E9", colour="black") +
  xlab("Feature") + ylab("Count") + ggtitle("Importance of a feature") +
  coord_flip()
```

#### Extra-tree Random Forest classifier

```{r}
# Set the random seed to make this result reproducible
set.seed(42)

# Create the "x" value, cf ?extraTrees
my.x <- men[,c(first.col.index:last.col.index)]
my.y <- as.factor(men[,c(match.col.index)])
  
# Feed a randomForest model
fit <- randomForest(x = my.x, y = my.y,
          importance=TRUE, 
          ntree=2000
)

# Get the importance of the features
importance.features <- tibble::rownames_to_column(data.frame(fit$importance[,c(1)]))
colnames(importance.features) <- c("rowname", "value")

# Plot the importance of the features for a man
ggplot(importance.features, aes(x = reorder(rowname, -value), y = value)) +
  geom_bar(stat = "identity", position = "dodge", fill="#56B4E9", colour="black") +
  xlab("Feature") + ylab("Count") + ggtitle("Importance of a feature") +
  coord_flip()
```

### For women
#### Preminilary analysis
```{r}
# Isolate the women from the dataset
women <- df[df$gender == "W",]

# Create vector without NAs to use forest
women <- women[complete.cases(women[first.col.index:last.col.index]),]

# Group women by iid
women.grouped.iid <- women %>%
  group_by(iid) %>%
  summarise(
    sum.match = sum(match)
  ) 

# Find the number of women per number of matches
n.match.women <- women.grouped.iid %>%
  group_by(sum.match) %>%
  summarise(
    my.n = n()
  )

# Plot number of match per man
ggplot(n.match.women, aes(x = sum.match, y = my.n)) +
  geom_bar(stat = "identity", position = "dodge", fill="#E69F00", colour="black") +
  xlab("Number of matches") + ylab("Count") + ggtitle("Number of women per number of matches")

# Isolate women with matches
women.matches <-  df[df$gender == "W" & df$match == 1,] 
```

#### Simple Random Forest classifier

```{r}
# Set the random seed to make this result reproducible
set.seed(50)
# Feed a randomForest model
fit <- randomForest(as.factor(match) ~ sports + tvsports + exercise + 
              dining + museums + art + music + hiking + gaming + clubbing + 
              reading + tv + theater + movies + concerts + shopping + yoga,
          data = women,
          importance=TRUE, 
          ntree=2000
)

# Get the importance of the features
importance.features <- tibble::rownames_to_column(data.frame(fit$importance[,c(1)]))
colnames(importance.features) <- c("rowname", "value")

# Plot the importance of the features for a man
ggplot(importance.features, aes(x = reorder(rowname, -value), y = value)) +
  geom_bar(stat = "identity", position = "dodge", fill="#56B4E9", colour="black") +
  xlab("Feature") + ylab("Count") + ggtitle("Importance of a feature") +
  coord_flip()
```

#### Extra-tree Random Forest classifier

```{r}
# Set the random seed to make this result reproducible
set.seed(42)

# Create the "x" value, cf ?extraTrees
my.x <- women[,c(first.col.index:last.col.index)]
my.y <- as.factor(women[,c(match.col.index)])
  
# Feed a randomForest model
fit <- randomForest(x = my.x, y = my.y,
          importance=TRUE, 
          ntree=2000
)

# Get the importance of the features
importance.features <- tibble::rownames_to_column(data.frame(fit$importance[,c(1)]))
colnames(importance.features) <- c("rowname", "value")

# Plot the importance of the features for a man
ggplot(importance.features, aes(x = reorder(rowname, -value), y = value)) +
  geom_bar(stat = "identity", position = "dodge", fill="#56B4E9", colour="black") +
  xlab("Feature") + ylab("Count") + ggtitle("Importance of a feature") +
  coord_flip()
```

```{r}

```

# Create data to feed Gephi
****

In this dataset, there are connections between people. It fits well for a graph analysis, and we will thus use Gephi to do so.

```{r}
# Isolate iid (1) -> pid (12)
gephi <- df[,c(1, 12)]
# Rename columns to match Gephi's prerequisites
names(gephi)[1] <- paste("Source")
names(gephi)[2] <- paste("Target")
# Convert Target into integer (to avoid having 10.0, 11.0...)
# We don't want to have ".0" to have a good analysis with Gephi
gephi$Target <- as.integer(gephi$Target)
# Write on disk
write_csv(gephi, "gephi.csv")
```
